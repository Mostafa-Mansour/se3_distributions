{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import quat_math\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from PIL import Image\n",
    "import scipy.io as scio\n",
    "from functools import partial\n",
    "from object_pose_utils.utils import to_np, to_var\n",
    "from object_pose_utils.utils.display import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = 20, 12\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Object Indices of Interest\n",
    "\n",
    "| Object Indices |[]()|[]()|\n",
    "|---|---|---|\n",
    "| __1.__ 002_master_chef_can | __8.__ 009_gelatin_box      | __15.__ 035_power_drill       |\n",
    "| __2.__ 003_cracker_box     | __9.__ 010_potted_meat_can  | __16.__ 036_wood_block        |\n",
    "| __3.__ 004_sugar_box       | __10.__ 011_banana          | __17.__ 037_scissors          |\n",
    "| __4.__ 005_tomato_soup_can | __11.__ 019_pitcher_base    | __18.__ 040_large_marker      |\n",
    "| __5.__ 006_mustard_bottle  | __12.__ 021_bleach_cleanser | __19.__ 051_large_clamp       |\n",
    "| __6.__ 007_tuna_fish_can   | __13.__ 024_bowl            | __20.__ 052_extra_large_clamp |\n",
    "| __7.__ 008_pudding_box     | __14.__ 025_mug             | __21.__ 061_foam_brick        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforms3d.quaternions import quat2mat, mat2quat\n",
    "\n",
    "def getPoseCNNQuat(data, obj):\n",
    "    pose_idx = np.where(data['rois'][:,1].flatten()==obj)[0]\n",
    "    if(len(pose_idx) == 0):\n",
    "        return None\n",
    "    else:\n",
    "        pose_idx = pose_idx[0]\n",
    "    pose = data['poses'][pose_idx]\n",
    "    q = pose[:4][[1,2,3,0]]\n",
    "    q /= np.linalg.norm(q)\n",
    "    t = pose[4:7]\n",
    "    return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YCB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_pose_utils.datasets.ycb_dataset import YcbDataset as YCBDataset\n",
    "from object_pose_utils.datasets.image_processing import ImageNormalizer\n",
    "from object_pose_utils.datasets.inplane_rotation_augmentation import InplaneRotator\n",
    "\n",
    "from object_pose_utils.datasets.pose_dataset import OutputTypes as otypes\n",
    "\n",
    "dataset_root = '/ssd0/datasets/ycb/YCB_Video_Dataset'\n",
    "object_list = list(range(1,22))\n",
    "mode = \"test\"\n",
    "\n",
    "output_format = [otypes.OBJECT_LABEL,\n",
    "                 otypes.QUATERNION, \n",
    "                 otypes.TRANSLATION, \n",
    "                 otypes.IMAGE_CROPPED,\n",
    "                 otypes.DEPTH_POINTS_MASKED_AND_INDEXES,\n",
    "                ]\n",
    "\n",
    "dataset = YCBDataset(dataset_root, mode=mode,\n",
    "                     object_list = list(range(1,22)),\n",
    "                     output_data = output_format,\n",
    "                     resample_on_error = False,\n",
    "                     add_syn_background = False,\n",
    "                     add_syn_noise = False,\n",
    "                     use_posecnn_data = True,\n",
    "                     #preprocessors = [InplaneRotator()],\n",
    "                     postprocessors = [ImageNormalizer()],\n",
    "                     image_size = [640, 480], num_points=1000)\n",
    "\n",
    "model_clouds = {}\n",
    "for object_id in object_list:\n",
    "    cloud_filename = '{}/models/{}/points.xyz'.format(dataset_root, dataset.classes[object_id])\n",
    "    model_clouds[object_id] = np.loadtxt(cloud_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dense_fusion.network import PoseNet, PoseNetGlobal, PoseRefineNet, PoseNetDropout\n",
    "\n",
    "df_weights = '/home/bokorn/src/DenseFusion/trained_checkpoints/ycb/pose_model_26_0.012863246640872631.pth'\n",
    "df_estimator = PoseNet(num_points = 1000, num_obj = 21)\n",
    "df_estimator.load_state_dict(torch.load(df_weights))\n",
    "df_estimator.cuda();\n",
    "df_estimator.eval();\n",
    "\n",
    "#df_refine_weights = '/home/bokorn/src/DenseFusion/trained_checkpoints/ycb/pose_refine_model_69_0.009449292959118935.pth'\n",
    "#df_refine_estimator = PoseRefineNet(num_points = 1000, num_obj = 21)\n",
    "#df_refine_estimator.load_state_dict(torch.load(df_refine_weights))\n",
    "#df_refine_estimator.cuda();\n",
    "#df_refine_estimator.eval();\n",
    "\n",
    "#df_dropout_weights = '/home/bokorn/src/DenseFusion/trained_models/ycb_dropout/pose_model_36_0.019743827587456554.pth'\n",
    "#df_dropout_estimator = PoseNetDropout(num_points = 1000, num_obj = 21)\n",
    "#df_dropout_estimator.load_state_dict(torch.load(df_dropout_weights))\n",
    "#df_dropout_estimator.cuda();\n",
    "#df_dropout_estimator.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc0ec27858d4b78b793730dff26157e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14025), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception on index 6530: Mask 0049/001052 has less than minimum number of pixels (31 < 50)\n",
      "Exception on index 6531: Mask 0049/001067 has less than minimum number of pixels (44 < 50)\n",
      "Exception on index 6556: Mask 0049/001319 has less than minimum number of pixels (47 < 50)\n",
      "Exception on index 6558: Mask 0049/001340 has less than minimum number of pixels (48 < 50)\n",
      "Exception on index 6837: Mask 0059/000037 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 6842: Mask 0059/000088 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 6861: Mask 0059/000162 has less than minimum number of pixels (2 < 50)\n",
      "Exception on index 6862: Mask 0059/000163 has less than minimum number of pixels (7 < 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception on index 12401: Mask 0048/000656 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 12412: Mask 0048/000806 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13051: Mask 0054/001882 has less than minimum number of pixels (48 < 50)\n",
      "Exception on index 13052: Mask 0054/001888 has less than minimum number of pixels (28 < 50)\n",
      "Exception on index 13054: Mask 0054/001918 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13558: Mask 0057/000830 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13579: Mask 0057/000940 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13580: Mask 0057/000942 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13587: Mask 0057/000965 has less than minimum number of pixels (12 < 50)\n",
      "Exception on index 13589: Mask 0057/000973 has less than minimum number of pixels (50 < 50)\n",
      "Exception on index 13595: Mask 0057/000991 has less than minimum number of pixels (12 < 50)\n",
      "Exception on index 13596: Mask 0057/000998 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13603: Mask 0057/001054 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13604: Mask 0057/001057 has less than minimum number of pixels (25 < 50)\n",
      "Exception on index 13605: Mask 0057/001066 has less than minimum number of pixels (8 < 50)\n",
      "Exception on index 13606: Mask 0057/001071 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13607: Mask 0057/001073 has less than minimum number of pixels (1 < 50)\n",
      "Exception on index 13608: Mask 0057/001076 has less than minimum number of pixels (16 < 50)\n",
      "Exception on index 13609: Mask 0057/001078 has less than minimum number of pixels (6 < 50)\n",
      "Exception on index 13610: Mask 0057/001081 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13611: Mask 0057/001082 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13612: Mask 0057/001083 has less than minimum number of pixels (2 < 50)\n",
      "Exception on index 13613: Mask 0057/001086 has less than minimum number of pixels (5 < 50)\n",
      "Exception on index 13614: Mask 0057/001087 has less than minimum number of pixels (37 < 50)\n",
      "Exception on index 13615: Mask 0057/001092 has less than minimum number of pixels (27 < 50)\n",
      "Exception on index 13617: Mask 0057/001099 has less than minimum number of pixels (3 < 50)\n",
      "Exception on index 13618: Mask 0057/001101 has less than minimum number of pixels (32 < 50)\n",
      "Exception on index 13619: Mask 0057/001108 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13621: Mask 0057/001118 has less than minimum number of pixels (2 < 50)\n",
      "Exception on index 13622: Mask 0057/001131 has less than minimum number of pixels (5 < 50)\n",
      "Exception on index 13625: Mask 0057/001138 has less than minimum number of pixels (2 < 50)\n",
      "Exception on index 13628: Mask 0057/001148 has less than minimum number of pixels (2 < 50)\n",
      "Exception on index 13638: Mask 0057/001181 has less than minimum number of pixels (3 < 50)\n",
      "Exception on index 13640: Mask 0057/001190 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13691: Mask 0057/001530 has less than minimum number of pixels (4 < 50)\n",
      "Exception on index 13695: Mask 0057/001549 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13696: Mask 0057/001560 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13698: Mask 0057/001566 has less than minimum number of pixels (44 < 50)\n",
      "Exception on index 13699: Mask 0057/001570 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13701: Mask 0057/001589 has less than minimum number of pixels (30 < 50)\n",
      "Exception on index 13702: Mask 0057/001593 has less than minimum number of pixels (37 < 50)\n",
      "Exception on index 13705: Mask 0057/001621 has less than minimum number of pixels (3 < 50)\n",
      "Exception on index 13706: Mask 0057/001628 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13708: Mask 0057/001647 has less than minimum number of pixels (29 < 50)\n",
      "Exception on index 13709: Mask 0057/001671 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13711: Mask 0057/001691 has less than minimum number of pixels (30 < 50)\n",
      "Exception on index 13714: Mask 0057/001705 has less than minimum number of pixels (11 < 50)\n",
      "Exception on index 13715: Mask 0057/001708 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13716: Mask 0057/001709 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13717: Mask 0057/001712 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13724: Mask 0057/001740 has less than minimum number of pixels (36 < 50)\n",
      "Exception on index 13728: Mask 0057/001747 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13729: Mask 0057/001748 has less than minimum number of pixels (0 < 50)\n",
      "Exception on index 13732: Mask 0057/001774 has less than minimum number of pixels (24 < 50)\n"
     ]
    }
   ],
   "source": [
    "from generic_pose.datasets.ycb_dataset import getYCBSymmeties\n",
    "from object_pose_utils.utils.pose_processing import symmetricAngularDistance\n",
    "from object_pose_utils.utils.pose_error import add, adi\n",
    "from quat_math import quaternion_matrix\n",
    "from generic_pose.utils.evaluation_utils import evaluateDenseFusion\n",
    "\n",
    "import pathlib\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "pose_gt = {obj:{} for obj in object_list}\n",
    "pose_est = {obj:{} for obj in object_list}\n",
    "sym_angular_error = {obj:{} for obj in object_list}\n",
    "add_error = {obj:{} for obj in object_list}\n",
    "add_sym_error = {obj:{} for obj in object_list}\n",
    "\n",
    "bad_data = []\n",
    "with torch.no_grad():\n",
    "    for j, data in enumerate(tqdm(dataset)):\n",
    "        obj, quat, trans, img, points, choose = data\n",
    "\n",
    "        if(len(obj) == 0):\n",
    "            bad_data.append(j)\n",
    "            continue\n",
    "\n",
    "        sym_axis, sym_ang = getYCBSymmeties(obj.item())\n",
    "        trans = to_np(trans)\n",
    "        \n",
    "        q_est, t_est, _ = evaluateDenseFusion(df_estimator, img, points, choose, obj)\n",
    "\n",
    "\n",
    "        mat = quaternion_matrix(quat)\n",
    "        err_ang = symmetricAngularDistance(torch.Tensor(q_est).unsqueeze(0), \n",
    "                                           quat.unsqueeze(0),\n",
    "                                           sym_axis, sym_ang).item()*180/np.pi\n",
    "        mat_est = quaternion_matrix(q_est)\n",
    "        err_add = add(mat[:3,:3], trans, mat_est[:3,:3], t_est, \n",
    "                      model_clouds[obj.item()])\n",
    "        err_adi = adi(mat[:3,:3], trans, mat_est[:3,:3], t_est, \n",
    "                      model_clouds[obj.item()])\n",
    "\n",
    "        pose_est[obj.item()][j]=(q_est, t_est)\n",
    "        pose_gt[obj.item()][j]=(to_np(quat), trans)\n",
    "        sym_angular_error[obj.item()][j]=err_ang\n",
    "        add_error[obj.item()][j]=err_add\n",
    "        add_sym_error[obj.item()][j]=err_adi\n",
    "        \n",
    "    np.savez('iros_results/dense_fusion.npz', \n",
    "             pose_gt=pose_gt,\n",
    "             pose_est=pose_est,\n",
    "             sym_angular_error=sym_angular_error,\n",
    "             add_error=add_error,\n",
    "             add_sym_error=add_sym_error,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#func(img, points, choose, obj)\n",
    "df_obj_idx = obj - 1\n",
    "img = img.unsqueeze(0).cuda()\n",
    "points = points.unsqueeze(0).cuda()\n",
    "choose = choose.unsqueeze(0).cuda()\n",
    "df_obj_idx = df_obj_idx.unsqueeze(0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.9146651 ,  0.17347349,  0.3600927 , -0.06023394], dtype=float32),\n",
       " array([0.11527348, 0.06846315, 0.8546898 ], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(q_est, t_est)\n",
    "#(quat, trans)\n",
    "#max_q, max_t, feat = evaluateDenseFusion(df_estimator, img, points, choose, obj, use_global_feat=False)\n",
    "#feat.shape\n",
    "#lik_est = evaluateFeature(comp_estimator, obj, feat, grid_features)\n",
    "#comp_estimator(feat_global)\n",
    "#plt.plot(to_np(lik_est.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master chef can\n",
      " & \\textbf{0.93} \\\\\n",
      "cracker box\n",
      " & \\textbf{2.36} \\\\\n",
      "sugar box\n",
      " & \\textbf{2.05} \\\\\n",
      "tomato soup can\n",
      " & \\textbf{1.42} \\\\\n",
      "mustard bottle\n",
      " & \\textbf{2.22} \\\\\n",
      "tuna fish can\n",
      " & \\textbf{0.08} \\\\\n",
      "pudding box\n",
      " & \\textbf{-1.17} \\\\\n",
      "gelatin box\n",
      " & \\textbf{2.39} \\\\\n",
      "potted meat can\n",
      " & \\textbf{0.63} \\\\\n",
      "banana\n",
      " & \\textbf{0.39} \\\\\n",
      "pitcher base\n",
      " & \\textbf{2.22} \\\\\n",
      "bleach cleanser\n",
      " & \\textbf{1.22} \\\\\n",
      "bowl\n",
      " & \\textbf{-0.38} \\\\\n",
      "mug\n",
      " & \\textbf{-1.28} \\\\\n",
      "power drill\n",
      " & \\textbf{1.75} \\\\\n",
      "wood block\n",
      " & \\textbf{-3.05} \\\\\n",
      "scissors\n",
      " & \\textbf{0.43} \\\\\n",
      "large marker\n",
      " & \\textbf{0.10} \\\\\n",
      "large clamp\n",
      " & \\textbf{-9.64} \\\\\n",
      "extra large clamp\n",
      " & \\textbf{-5.50} \\\\\n",
      "foam brick\n",
      " & \\textbf{-2.42} \\\\\n",
      "\\hline\n",
      "All \n",
      " & \\textbf{0.07} \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(makeTableEntries(likelihood, val_func=mean_log_clean, bold_func = max, individual = True))\n",
    "#makeTable(sym_angular_error, val_func=mean_abs, bold_func = min, individual = True)\n",
    "#print('\\n\\n\\n')\n",
    "#makeTable(add_error, val_func=mean_abs, bold_func = min, individual = True)\n",
    "#print('\\n\\n\\n')\n",
    "#makeTable(add_sym_error, val_func=mean_abs, bold_func = min, individual = True)\n",
    "#print('\\n\\n\\n')\n",
    "#makeTableEntries(sym_angular_error_mode, val_func=mean_abs, bold_func = min, individual = True)\n",
    "#print('\\n\\n\\n')\n",
    "#makeTableEntries(add_error_mode, val_func=mean_abs, bold_func = min, individual = True)\n",
    "#print('\\n\\n\\n')\n",
    "#makeTableEntries(add_sym_error_mode, val_func=mean_abs, bold_func = min, individual = True)\n",
    "#print('\\n\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Symmetric \n",
      " & \\textbf{1.10} \\\\\n",
      "\n",
      "Symmetric \n",
      " & \\textbf{-5.22} \\\\\n",
      "\n",
      "All \n",
      " & \\textbf{0.07} \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(makeTableEntries(likelihood, objs = non_sym_objs, val_func=mean_log_clean, bold_func = max, agg_title = 'Non-Symmetric'))\n",
    "print(makeTableEntries(likelihood, objs = sym_objs, val_func=mean_log_clean, bold_func = max, agg_title = 'Symmetric'))\n",
    "print(makeTableEntries(likelihood, val_func=mean_log_clean, bold_func = max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histLikelihood(lik_est, quat, k = 4):\n",
    "    if(type(lik_est) is torch.Tensor):\n",
    "        lik_est = to_np(lik_est.flatten())\n",
    "    tetra_interp.setValues(lik_est)\n",
    "    lik = tetra_interp.smooth(to_np(quat), k=k).item()\n",
    "    return lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lik_est, q_est, t_est = lik_funcs['hist_conf'](img, points, choose, obj)\n",
    "\n",
    "tetra_interp.setValues(lik_est)\n",
    "d, j = tetra_interp.kd_grid.query(to_np(quat), k=20)\n",
    "\n",
    "print(lik_est[j])\n",
    "max_idx = np.argmax(lik_est)\n",
    "q_max = grid_vertices[max_idx]\n",
    "print(tetra_interp.smooth(to_np(q_max), k=k).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = quatAngularDiffBatch(to_np(quat), to_np(grid_vertices))\n",
    "np.argsort(dists)[max_idx]\n",
    "dists[max_idx]*180/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(histLikelihood(np.ones(grid_size), quat, k = 3885))\n",
    "\n",
    "lik_est, q_est, t_est = lik_funcs['hist_reg_global'](img, points, choose, obj)\n",
    "print(lik_est.shape)\n",
    "print(histLikelihood(lik_est, quat, k = 3885), lik_est.min(), lik_est.max())\n",
    "\n",
    "lik_est, q_est, t_est = lik_funcs['hist_conf'](img, points, choose, obj)\n",
    "print(lik_est.shape)\n",
    "print(histLikelihood(lik_est, quat, k = 3885), lik_est.min(), lik_est.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterSO3New(vertices, vals = None, q_gt = None,\n",
    "                   clims = None, \n",
    "                   alims = [0.,1.], \n",
    "                   s=None,\n",
    "                   ax = None, cmap = 'jet'):\n",
    "   \n",
    "    if(type(cmap) == str):\n",
    "        cmap = plt.get_cmap(cmap)\n",
    "    if(ax is None):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1,1,1, projection='3d')\n",
    "\n",
    "    #c = cmap(vals)\n",
    "    if(vals is not None):\n",
    "        if(clims is not None):\n",
    "            c_min, c_max = clims\n",
    "        else:\n",
    "            c_min, c_max = min(vals), max(vals)\n",
    "            \n",
    "        a = np.maximum(0,np.minimum(1, (vals - c_min)/(c_max - c_min)))\n",
    "        c = cmap(a)\n",
    "        alpha_min, alpha_max = alims\n",
    "        c[:,3] = (alpha_max-alpha_min)*a + alpha_min\n",
    "    else:\n",
    "        a = 1\n",
    "        c = None\n",
    "\n",
    "    if(s is None):\n",
    "        s = a*10\n",
    "    pts = quats2Point(vertices)\n",
    "    h = ax.scatter(pts[:,0], pts[:,1], pts[:,2], s=s, c=c)\n",
    "\n",
    "    if(q_gt is not None):\n",
    "        pt_gt = quats2Point(q_gt)\n",
    "        ax.scatter(pt_gt[:,0], pt_gt[:,1], pt_gt[:,2], c='r', marker='x')\n",
    "\n",
    "    return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pylab.rcParams['figure.figsize'] = 20, 12\n",
    "\n",
    "#idx = 12492 #np.random.randint(len(dataset))\n",
    "idx = np.random.randint(len(dataset))\n",
    "data = dataset[idx]\n",
    "obj, quat, trans, img, points, choose = data\n",
    "print(obj)\n",
    "max_q, max_t, feat = evaluateDenseFusion(df_global_estimator, img, points, choose, obj)\n",
    "\n",
    "imshowTorch(img, normalized=True)\n",
    "\n",
    "knn_k = 200\n",
    "\n",
    "max_pt = quats2Point([max_q])\n",
    "gt_pt = quats2Point([to_np(quat)])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,4,1, projection='3d')\n",
    "\n",
    "print('Uniform: {}'.format(histLikelihood(np.ones(grid_size), quat, k = knn_k)))\n",
    "\n",
    "#lik_est = evaluateFeature(reg_estimator, obj, feat, grid_features)\n",
    "key = 'hist_reg_global'\n",
    "lik_est, q_est, t_est = lik_funcs[key](img, points, choose, obj)\n",
    "print('{}: {}'.format(key, histLikelihood(lik_est, quat, k = knn_k)))\n",
    "#lik_est = lik_est > .001\n",
    "scatterSO3New(to_np(grid_vertices), lik_est, ax=ax, clims = [0,.3], alims = [0,1], s=10)\n",
    "ax.scatter(max_pt[:,0], max_pt[:,1], max_pt[:,2], c='k', s=100, marker='x')\n",
    "ax.scatter(gt_pt[:,0], gt_pt[:,1], gt_pt[:,2], c='g',s=100, marker='x')\n",
    "\n",
    "ax = fig.add_subplot(1,4,2, projection='3d')\n",
    "\n",
    "key = 'hist_reg_idv_global'\n",
    "lik_est, q_est, t_est = lik_funcs[key](img, points, choose, obj)\n",
    "print('{}: {}'.format(key, histLikelihood(lik_est, quat, k = knn_k)))\n",
    "#lik_est = lik_est > .001\n",
    "scatterSO3New(to_np(grid_vertices), lik_est, ax=ax, clims = [0,.3], alims = [0,1], s=10)\n",
    "ax.scatter(max_pt[:,0], max_pt[:,1], max_pt[:,2], c='k', s=100, marker='x')\n",
    "ax.scatter(gt_pt[:,0], gt_pt[:,1], gt_pt[:,2], c='g', s=100, marker='x')\n",
    "\n",
    "key = 'hist_comp_global'\n",
    "ax = fig.add_subplot(1,4,3, projection='3d')\n",
    "lik_est, q_est, t_est = lik_funcs[key](img, points, choose, obj)\n",
    "print('{}: {}'.format(key, histLikelihood(lik_est, quat, k = knn_k)))\n",
    "#lik_est = lik_est > .001\n",
    "scatterSO3New(to_np(grid_vertices), lik_est, ax=ax, clims = [0,.3], alims = [0,1], s=10)\n",
    "ax.scatter(max_pt[:,0], max_pt[:,1], max_pt[:,2], c='k', s=100, marker='x')\n",
    "ax.scatter(gt_pt[:,0], gt_pt[:,1], gt_pt[:,2], c='g', s=100, marker='x')\n",
    "\n",
    "key = 'hist_conf'\n",
    "ax = fig.add_subplot(1,4,4, projection='3d')\n",
    "lik_est, q_est, t_est = lik_funcs[key](img, points, choose, obj)\n",
    "print('{}: {}'.format(key, histLikelihood(lik_est, quat, k = knn_k)))\n",
    "#lik_est = lik_est > .001\n",
    "scatterSO3New(to_np(grid_vertices), lik_est, ax=ax, clims = [0,.3], alims = [0,1], s=10)\n",
    "ax.scatter(max_pt[:,0], max_pt[:,1], max_pt[:,2], c='k', s=100, marker='x')\n",
    "ax.scatter(gt_pt[:,0], gt_pt[:,1], gt_pt[:,2], c='g', s=100, marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1, projection='3d')\n",
    "\n",
    "lik_est, q_est, t_est = lik_funcs['hist_conf'](img, points, choose, obj)\n",
    "#lik_est, q_est, t_est = lik_funcs['hist_reg_idv_global'](img, points, choose, obj)\n",
    "scatterSO3New(to_np(grid_vertices), lik_est, [to_np(quat)], ax=ax, clims = [0,.3], alims = [0,1], s=1000)\n",
    "gt_pt = quats2Point([to_np(quat)])\n",
    "ax.scatter(gt_pt[:,0], gt_pt[:,1], gt_pt[:,2], c='b',s=100, marker='x')\n",
    "#scatterSO3New(to_np(grid_vertices), dists < np.pi/2., [to_np(quat)], ax=ax, clims = [0,1], alims = [0,.01], s=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (bpy)",
   "language": "python",
   "name": "bpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
