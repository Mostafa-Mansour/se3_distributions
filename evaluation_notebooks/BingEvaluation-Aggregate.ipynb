{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import quat_math\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from PIL import Image\n",
    "import scipy.io as scio\n",
    "from functools import partial\n",
    "from object_pose_utils.utils import to_np, to_var\n",
    "from object_pose_utils.utils.display import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = 20, 12\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Object Indices of Interest\n",
    "\n",
    "| Object Indices |[]()|[]()|\n",
    "|---|---|---|\n",
    "| __1.__ 002_master_chef_can | __8.__ 009_gelatin_box      | __15.__ 035_power_drill       |\n",
    "| __2.__ 003_cracker_box     | __9.__ 010_potted_meat_can  | __16.__ 036_wood_block        |\n",
    "| __3.__ 004_sugar_box       | __10.__ 011_banana          | __17.__ 037_scissors          |\n",
    "| __4.__ 005_tomato_soup_can | __11.__ 019_pitcher_base    | __18.__ 040_large_marker      |\n",
    "| __5.__ 006_mustard_bottle  | __12.__ 021_bleach_cleanser | __19.__ 051_large_clamp       |\n",
    "| __6.__ 007_tuna_fish_can   | __13.__ 024_bowl            | __20.__ 052_extra_large_clamp |\n",
    "| __7.__ 008_pudding_box     | __14.__ 025_mug             | __21.__ 061_foam_brick        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforms3d.quaternions import quat2mat, mat2quat\n",
    "\n",
    "def getPoseCNNQuat(data, obj):\n",
    "    pose_idx = np.where(data['rois'][:,1].flatten()==obj)[0]\n",
    "    if(len(pose_idx) == 0):\n",
    "        return None, None\n",
    "    else:\n",
    "        pose_idx = pose_idx[0]\n",
    "    pose = data['poses'][pose_idx]\n",
    "    q = pose[:4][[1,2,3,0]]\n",
    "    q /= np.linalg.norm(q)\n",
    "    t = pose[4:7]\n",
    "    return q, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YCB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_pose_utils.datasets.ycb_dataset import YcbDataset as YCBDataset\n",
    "from object_pose_utils.datasets.pose_dataset import OutputTypes as otypes\n",
    "from object_pose_utils.datasets.feature_dataset import  FeatureDataset\n",
    "dataset_root = '/ssd0/datasets/ycb/YCB_Video_Dataset'\n",
    "object_list = list(range(1,22))\n",
    "mode = \"valid\"\n",
    "\n",
    "feature_root = '/scratch/bokorn/results/posecnn_feat_all/'\n",
    "feature_key = 'fc6'\n",
    "feature_size = 4096\n",
    "\n",
    "output_format = [otypes.OBJECT_LABEL,\n",
    "                 otypes.QUATERNION, \n",
    "                 otypes.TRANSLATION, \n",
    "                 otypes.TRANSFORM_MATRIX,\n",
    "                ]\n",
    "\n",
    "ycb_dataset = YCBDataset(dataset_root, mode=mode,\n",
    "                     object_list = object_list,\n",
    "                     output_data = output_format,\n",
    "                     resample_on_error = False,\n",
    "                     add_syn_background = False,\n",
    "                     add_syn_noise = False,\n",
    "                     #use_posecnn_data = True,\n",
    "                     #preprocessors = [InplaneRotator()],\n",
    "                     #postprocessors = [ImageNormalizer()],\n",
    "                     image_size = [640, 480], num_points=1000)\n",
    "\n",
    "dataset = FeatureDataset(dataset_root = dataset_root,\n",
    "                         feature_root = feature_root,\n",
    "                         feature_key = feature_key,\n",
    "                         return_pred = True,\n",
    "                         mode = mode,\n",
    "                         resample_on_error = False,\n",
    "                         object_list = list(range(1,22)))\n",
    "\n",
    "model_clouds = {}\n",
    "for object_id in object_list:\n",
    "    cloud_filename = '{}/models/{}/points.xyz'.format(dataset_root, dataset.classes[object_id])\n",
    "    model_clouds[object_id] = np.loadtxt(cloud_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weights = '/home/bokorn/src/DenseFusion/trained_checkpoints/ycb/pose_model_26_0.012863246640872631.pth'\n",
    "df_refine_weights = '/home/bokorn/src/DenseFusion/trained_checkpoints/ycb/pose_refine_model_69_0.009449292959118935.pth'\n",
    "\n",
    "df_results_filename = 'results_valid_df_' + '.'.join(df_weights.split('/')[-1].split('.')[:-1])\n",
    "if(df_refine_weights is not None):\n",
    "    df_results_filename += '_' + '.'.join(df_refine_weights.split('/')[-1].split('.')[:-1])\n",
    "df_results_filename += '.pkl'\n",
    "\n",
    "with open(df_results_filename, 'rb') as f:\n",
    "    df_results = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_valid_df_pose_model_13_0.02780649198161978_pose_refine_model_69_0.009449292959118935.pkl\r\n",
      "results_valid_df_pose_model_26_0.012863246640872631_pose_refine_model_69_0.009449292959118935.pkl\r\n"
     ]
    }
   ],
   "source": [
    "ls results_valid_df_pose_model_*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_pose_utils.utils.pose_processing import quatAngularDiffBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_pose_utils.utils.interpolation import BinghamInterpolation\n",
    "\n",
    "if(False):\n",
    "    from object_pose_utils.utils.bingham import isobingham_likelihood\n",
    "\n",
    "    sigmas_data = np.load('/home/bokorn/src/generic_pose/generic_pose/notebooks/fc6_sigma.npz', allow_pickle=True)\n",
    "    sigmas = sigmas_data['sigmas'].item()\n",
    "\n",
    "    def bing_fixed(res, obj):\n",
    "        feat, pred_q, pred_t = res\n",
    "        bingham = BinghamInterpolation(pred_q.unsqueeze(0).cuda(), \n",
    "                                       torch.ones(1).cuda(), \n",
    "                                       sigma=torch.Tensor([sigmas[obj.item()]]).cuda())\n",
    "        return bingham, pred_q, pred_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/scratch/bokorn/results/log_lik/posecnn_fc6_iso/lr_1e-6/2019-09-07_16-10-58/weights/best_quat.pth', '/scratch/bokorn/results/log_lik/posecnn_fc6_iso/lr_1e-6/2019-09-07_16-10-58/weights/checkpoint_524000.pth']\n"
     ]
    }
   ],
   "source": [
    "from generic_pose.models.bingham_networks import IsoBingham\n",
    "from generic_pose.losses.bingham_loss import isoLikelihood\n",
    "\n",
    "if(True):\n",
    "    #feature_size = 1024\n",
    "    feature_size = 4096\n",
    "    #iso_model_checkpoint_pattern = '/scratch/bokorn/results/log_lik/posecnn_fc6_iso/**/weights/checkpoint_*.pth'\n",
    "    #iso_model_checkpoint = sorted(glob.glob(iso_model_checkpoint_pattern,\n",
    "    #                                        recursive=True))[-1]\n",
    "    iso_model_checkpoint = '/scratch/bokorn/results/log_lik/posecnn_fc6_iso/lr_1e-6/2019-09-07_16-10-58/weights/best_quat.pth'\n",
    "    print(glob.glob('/'.join(iso_model_checkpoint.split('/')[:-1]) + '/*', recursive=True))\n",
    "\n",
    "    iso_estimator = IsoBingham(feature_size, len(object_list))\n",
    "    iso_estimator.load_state_dict(torch.load(iso_model_checkpoint))\n",
    "    iso_estimator.eval()\n",
    "    iso_estimator.cuda()\n",
    "\n",
    "    def bing_iso(res, obj):\n",
    "        feat, pred_q, pred_t = res\n",
    "        \n",
    "        feat = torch.Tensor(feat).unsqueeze(0).cuda()\n",
    "        mean_est = torch.Tensor(pred_q).unsqueeze(0).cuda()\n",
    "        df_obj = torch.LongTensor(obj-1).unsqueeze(0).cuda()\n",
    "        sig_est = iso_estimator(feat.unsqueeze(0).cuda(), df_obj)\n",
    "        lik_est = isoLikelihood(mean_q=mean_est[0], \n",
    "                                sig=sig_est[0,0])\n",
    "        \n",
    "        return lik_est, pred_q, pred_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41456"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7cfe7a6bdb54f94bfde98d8fabc8e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=41456), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception on index 11695: [Errno 2] No such file or directory: '/scratch/bokorn/results/posecnn_feat_all/data/0090/000617_007_tuna_fish_can_feat.npz'\n",
      "Exception on index 19642: [Errno 2] No such file or directory: '/scratch/bokorn/results/posecnn_feat_all/data/0087/000214_010_potted_meat_can_feat.npz'\n",
      "Exception on index 19643: [Errno 2] No such file or directory: '/scratch/bokorn/results/posecnn_feat_all/data/0087/000215_010_potted_meat_can_feat.npz'\n",
      "Exception on index 19644: [Errno 2] No such file or directory: '/scratch/bokorn/results/posecnn_feat_all/data/0087/000216_010_potted_meat_can_feat.npz'\n",
      "Exception on index 19645: [Errno 2] No such file or directory: '/scratch/bokorn/results/posecnn_feat_all/data/0087/000217_010_potted_meat_can_feat.npz'\n",
      "Exception on index 19647: [Errno 2] No such file or directory: '/scratch/bokorn/results/posecnn_feat_all/data/0087/000219_010_potted_meat_can_feat.npz'\n",
      "Exception on index 19649: [Errno 2] No such file or directory: '/scratch/bokorn/results/posecnn_feat_all/data/0087/000221_010_potted_meat_can_feat.npz'\n",
      "Exception on index 19650: [Errno 2] No such file or directory: '/scratch/bokorn/results/posecnn_feat_all/data/0087/000222_010_potted_meat_can_feat.npz'\n",
      "Exception on index 19651: [Errno 2] No such file or directory: '/scratch/bokorn/results/posecnn_feat_all/data/0087/000223_010_potted_meat_can_feat.npz'\n",
      "Exception on index 19653: [Errno 2] No such file or directory: '/scratch/bokorn/results/posecnn_feat_all/data/0087/000225_010_potted_meat_can_feat.npz'\n",
      "Exception on index 35982: [Errno 2] No such file or directory: '/scratch/bokorn/results/posecnn_feat_all/data/0090/000463_051_large_clamp_feat.npz'\n",
      "Exception on index 35983: [Errno 2] No such file or directory: '/scratch/bokorn/results/posecnn_feat_all/data/0090/000464_051_large_clamp_feat.npz'\n",
      "Exception on index 35984: [Errno 2] No such file or directory: '/scratch/bokorn/results/posecnn_feat_all/data/0090/000465_051_large_clamp_feat.npz'\n",
      "Exception on index 40807: [Errno 2] No such file or directory: '/scratch/bokorn/results/posecnn_feat_all/data/0091/000241_061_foam_brick_feat.npz'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    from object_pose_utils.utils.interpolation import TetraInterpolation, BinghamInterpolation\n",
    "    from generic_pose.losses.bingham_loss import isoLikelihood, duelLikelihood\n",
    "\n",
    "    import pathlib\n",
    "\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "    pcnn_gt = {obj:[] for obj in object_list}\n",
    "    pcnn_est = {obj:[] for obj in object_list}\n",
    "\n",
    "    df_gt = {obj:[] for obj in object_list}\n",
    "    df_est = {obj:[] for obj in object_list}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for j, data in enumerate(tqdm(dataset)):\n",
    "            obj, quat, trans, _ = ycb_dataset[j]\n",
    "            _, feat, quat_gt, quat_pred = data\n",
    "            posecnn_path = '{}/data/{}-posecnn.mat'.format(dataset.dataset_root, dataset.getPath(j))\n",
    "            posecnn_data = scio.loadmat(posecnn_path)\n",
    "            pred_q, pred_t = getPoseCNNQuat(posecnn_data, obj.item())\n",
    "            if(len(obj) == 0):\n",
    "                continue\n",
    "\n",
    "            if(pred_q is not None):\n",
    "                pcnn_gt[obj.item()].append(quat.float())\n",
    "                pcnn_est[obj.item()].append(torch.Tensor(pred_q))\n",
    "\n",
    "            if(j in df_results.keys()):\n",
    "                res = df_results[j]\n",
    "                if(res is not None):\n",
    "                    df_gt[obj.item()].append(quat.float())\n",
    "                    df_est[obj.item()].append(torch.Tensor(res['max_q']).float())\n",
    "\n",
    "    for obj in object_list:\n",
    "        df_gt[obj] = torch.stack(df_gt[obj])\n",
    "        df_est[obj] = torch.stack(df_est[obj])\n",
    "        pcnn_gt[obj] = torch.stack(pcnn_gt[obj])\n",
    "        pcnn_est[obj] = torch.stack(pcnn_est[obj])\n",
    "    \n",
    "    np.savez('val_quats.npz', \n",
    "         df_gt=df_gt,\n",
    "         df_est=df_est,\n",
    "         pcnn_gt=pcnn_gt,\n",
    "         pcnn_est=pcnn_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generic_pose.losses.bingham_loss import isoLoss\n",
    "q_gt = df_gt[1].cuda()\n",
    "q_df = df_est[1].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.6448, device='cuda:0'), tensor(2.0323, device='cuda:0'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sig = \n",
    "    sig = torch.Tensor([[10]]).repeat(q_gt.shape[0], 1).cuda()\n",
    "isoLoss(q_df, sig, q_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3285,  0.8043,  0.3770,  0.3211],\n",
       "        [ 0.3299,  0.8038,  0.3766,  0.3214],\n",
       "        [ 0.3279,  0.8050,  0.3759,  0.3213],\n",
       "        ...,\n",
       "        [-0.6503,  0.6982, -0.2303, -0.1913],\n",
       "        [-0.6499,  0.6994, -0.2292, -0.1898],\n",
       "        [-0.6509,  0.6990, -0.2283, -0.1884]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8719625980246123"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (bpy)",
   "language": "python",
   "name": "bpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
